{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import shutil\n",
    "import requests\n",
    "from reportlab.lib.pagesizes import letter\n",
    "from reportlab.pdfgen import canvas\n",
    "from PyPDF2 import PdfMerger"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_image_urls(manga_chapter_link, verbose=0):\n",
    "    data = requests.get(manga_chapter_link).text\n",
    "    start_marker = \"<p id=arraydata style=display:none>\"\n",
    "    end_marker = \"</p>\\r\"\n",
    "\n",
    "    # Find the position of the first occurrence of start_marker\n",
    "    start_index = data.find(start_marker)\n",
    "\n",
    "    # Check if start_marker is found\n",
    "    if start_index != -1:\n",
    "        # Find the position of the first occurrence of end_marker after start_index\n",
    "        end_index = data.find(end_marker, start_index + len(start_marker))\n",
    "        \n",
    "        # Check if end_marker is found after start_marker\n",
    "        if end_index != -1:\n",
    "            # Extract the substring between start_index and end_index\n",
    "            result = data[start_index + len(start_marker):end_index]\n",
    "            result = result.split(\",\")\n",
    "            if verbose > 0:\n",
    "                print(\"found \" + str(len(result)) + \" pages\")\n",
    "        else:\n",
    "            print(\"end_marker not found after \" + start_marker)\n",
    "    else:\n",
    "        print(start_marker + \" not found\")\n",
    "\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_all_chapter_urls(main_page_url):\n",
    "    data = requests.get(main_page_url).text\n",
    "    \n",
    "    start = data.rindex(\"<!-- content-->\")\n",
    "    end = start + data[start:].index(\"</ul>\")\n",
    "\n",
    "    pattern = r\"href=\\\"(.*?)\\\"\"\n",
    "    return list(reversed(re.findall(pattern, data[start:end])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_chapter_images(chapter_image_urls, manga_name, chapter):\n",
    "    # Create a directory to save the downloaded images\n",
    "    if not os.path.exists('./downloaded_images'):\n",
    "        os.makedirs('./downloaded_images')\n",
    "    if not os.path.exists(os.path.join('./downloaded_images',manga_name)):\n",
    "        os.makedirs(os.path.join('./downloaded_images',manga_name))\n",
    "    if not os.path.exists(os.path.join('./downloaded_images',manga_name,chapter)):\n",
    "        os.makedirs(os.path.join('./downloaded_images',manga_name,chapter))\n",
    "\n",
    "    # Download and save each image locally\n",
    "    for i, image_url in enumerate(chapter_image_urls):\n",
    "        response = requests.get(image_url)\n",
    "        if response.status_code == 200:\n",
    "            with open(os.path.join('./downloaded_images',manga_name,chapter,'image_'+str(i+ 1)+'.png'), 'wb') as image_file:\n",
    "                image_file.write(response.content)\n",
    "        else:\n",
    "            print(\"failed to download page\", i + 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_PDF_from_images(manga_name, chapter, verbose=0):\n",
    "    if not os.path.exists('./Manga_PDFs'):\n",
    "        os.makedirs('./Manga_PDFs')\n",
    "    if not os.path.exists(os.path.join('./Manga_PDFs',manga_name)):\n",
    "        os.makedirs(os.path.join('./Manga_PDFs',manga_name))\n",
    "\n",
    "    # Output PDF file path\n",
    "    output_pdf_path = os.path.join('./Manga_PDFs',manga_name,chapter+'.pdf')\n",
    "\n",
    "    # Create a PDF document\n",
    "    c = canvas.Canvas(output_pdf_path, pagesize=letter)\n",
    "    width, height = letter\n",
    "\n",
    "    # sort the images according to page number\n",
    "    path = os.path.join(\"./downloaded_images\", manga_name, chapter)\n",
    "    images = os.listdir(path)\n",
    "    images.sort(key=lambda x: int(x.split('.')[0].split(\"_\")[1]))\n",
    "    image_paths = [os.path.join(path, x) for x in images]\n",
    "\n",
    "    for image_path in image_paths:\n",
    "        # Add the image to the PDF page, maintaining the aspect ratio\n",
    "        c.drawImage(image_path, 0, 0, width, height, preserveAspectRatio=True)\n",
    "        c.showPage()\n",
    "\n",
    "    # Add a white blank page at the end\n",
    "    c.showPage()\n",
    "\n",
    "    # Save the PDF document\n",
    "    c.save()\n",
    "\n",
    "    if verbose > 0:\n",
    "        print(f'PDF saved as \"{output_pdf_path}\"')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_pdf_files(path_to_pdfs, list_of_chapter_names, path_of_merge):\n",
    "    pdf_merger = PdfMerger()\n",
    "\n",
    "    for pdf_file in list_of_chapter_names:\n",
    "        pdf_merger.append(os.path.join(path_to_pdfs, pdf_file))\n",
    "\n",
    "    with open(path_of_merge, 'wb') as output:\n",
    "        pdf_merger.write(output)\n",
    "\n",
    "    pdf_merger.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_manga_pdf_folder(manga_pdf_folder_path, merge_step = 10, verbose=0):\n",
    "    merge_folder_path = os.path.join(os.path.split(manga_pdf_folder_path)[0], os.path.split(manga_pdf_folder_path)[1] + \"_merged\")\n",
    "    os.makedirs(merge_folder_path)\n",
    "\n",
    "    chapter_pdfs = [f for f in os.listdir(manga_pdf_folder_path) if f.endswith('.pdf')]\n",
    "    chapter_pdfs.sort(key=lambda x: int(x.split('.')[0]))\n",
    "\n",
    "    for i in range(0, len(chapter_pdfs), merge_step):\n",
    "        chapters_to_merge = chapter_pdfs[i: i + merge_step]\n",
    "        title = \"Chapters \" + str(chapters_to_merge[0].split(\".\")[0]) + \"-\" + str(chapters_to_merge[-1].split(\".\")[0])\n",
    "        merge_path = os.path.join(merge_folder_path, title)\n",
    "        merge_pdf_files(manga_pdf_folder_path, chapters_to_merge, merge_path)\n",
    "        \n",
    "        for chapter_pdf in chapters_to_merge:\n",
    "            os.remove(os.path.join(manga_pdf_folder_path, chapter_pdf))\n",
    "\n",
    "        if verbose > 0:\n",
    "            print(\"merged\", title, \"into\", merge_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def double_check_chapters(main_page_url, manga_name):\n",
    "    chapter_pdfs = os.listdir(os.path.join('./Manga_PDFs',manga_name))\n",
    "\n",
    "    all_chapter_urls = get_all_chapter_urls(main_page_url)\n",
    "    all_chapter_urls = [x.split(\"-\")[-1]+\".pdf\" for x in all_chapter_urls]\n",
    "\n",
    "    return list(set(all_chapter_urls).difference(set(chapter_pdfs)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_manga_from_main_page_url(main_page_url, manga_name, merge_step=10, verbose=0):\n",
    "    manga_name = manga_name.replace(\" \", \"_\")\n",
    "    chapter_urls = get_all_chapter_urls(main_page_url)\n",
    "    \n",
    "    for manga_chapter_link in chapter_urls:\n",
    "        chapter = manga_chapter_link.split(\"-\")[-1]\n",
    "        if verbose > 0:\n",
    "            print(\"processing chapter:\", chapter)\n",
    "\n",
    "        image_urls = get_image_urls(manga_chapter_link, verbose=verbose-1)\n",
    "        download_chapter_images(image_urls, manga_name, chapter)\n",
    "        create_PDF_from_images(manga_name, chapter, verbose=verbose-1)\n",
    "\n",
    "        if verbose > 0:\n",
    "            print(\"deleting downloaded images for chapter\", chapter)\n",
    "        shutil.rmtree(os.path.join('./downloaded_images',manga_name,chapter))\n",
    "    shutil.rmtree(os.path.join('./downloaded_images',manga_name))\n",
    "\n",
    "    missing_chapters = double_check_chapters(main_page_url, manga_name)\n",
    "    if len(missing_chapters) != 0:\n",
    "        print(\" \".join(missing_chapters), \"are missing, abort mission!\")\n",
    "        return\n",
    "\n",
    "    merge_manga_pdf_folder(os.path.join(\"./Manga_PDFs\", manga_name), merge_step = merge_step, verbose=verbose-1)\n",
    "\n",
    "    shutil.rmtree(os.path.join('./Manga_PDFs/',manga_name))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Auto Download"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "main_page_url = \"https://mangapanda.in/manga/planetes\"\n",
    "download_manga_from_main_page_url(main_page_url, \"planetes2\", merge_step=7, verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Manual download  \n",
    "\n",
    "- Try manually downloading the chapters if auto download fails because of websites broken chapter page urls  \n",
    "- You can detect the broken chapter page urls by this error:  \n",
    "\"fileName=<_io.BufferedReader name=PATH/OF/BROKEN/PNG identity=[ImageReader@0x7f6f650d5b20] cannot identify image file <_io.BytesIO object at 0x7f6f650d2ea0>\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_manga_with_list(manga_link, manga_name, chapter_list):\n",
    "    for chapter in chapter_list:\n",
    "        manga_chapter_link = manga_link + chapter\n",
    "\n",
    "        print(\"processing chapter:\", chapter)\n",
    "\n",
    "        try:\n",
    "            image_urls = get_image_urls(manga_chapter_link)\n",
    "        except Exception as e:\n",
    "            print(\"error during geting image urls\\n\", e)\n",
    "            break\n",
    "\n",
    "        try:\n",
    "            download_chapter_images(image_urls, manga_name, chapter)\n",
    "        except Exception as e:\n",
    "            print(\"error during dowloading images\\n\", e)\n",
    "            break\n",
    "\n",
    "        try:\n",
    "            create_PDF_from_images(image_urls, manga_name, chapter)\n",
    "        except Exception as e:\n",
    "            print(\"error during creating pdf\\n\", e)\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"manga_link = \"https://mangapanda.in/planetes-chapter-\"\n",
    "manga_name = \"planetes\"\n",
    "chapter_list = [\"1\",\"2\",\"3\",\"4\",\"5\",\"6\",\"7\",\"8\",\"9\",\"10\",\"11\",\"12\",\"13\",\"14\",\"15\",\"16\",\"17\",\"18\",\"19\",\"20\",\"21\",\"22\",\"23\",\"24\",\"25\",\"26\"]\n",
    "\n",
    "download_manga_with_list(manga_link, manga_name, chapter_list)\n",
    "merge_manga_pdf_folder(\"./Manga_PDFs/fire punch\", merge_step = 10)\"\"\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.6 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
